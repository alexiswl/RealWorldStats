{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the footy stats <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set indexes\n",
    "Indexes will bind to be columns of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index = [\"BindKey\",  \n",
    "              \"Kicks\", \"Marks\", \"Handballs\", \"Disposals\", \"Goals\", \"Behinds\", \"HitOuts\",\n",
    "              \"Tackles\", \"Rebound50s\", \"Inside50s\", \"Clearances\", \"Clangers\", \n",
    "              \"FreesFor\", \"FreesAgainst\", \"BrownlowVotes\", \n",
    "              \"ContestedPossesions\", \"UncontestedPossesions\", \n",
    "              \"ContestedMarks\", \"MarksInside50s\",  \"OnePercenters\", \"Bounces\",\n",
    "              \"GoalAssist\"]\n",
    "\n",
    "metadata_index = [\"Date\", \"Team_home\", \"Team_away\", \n",
    "                  \"Quarters_home\", \"Quarters_away\", \n",
    "                  \"Total_home\", \"Total_away\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define match data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_data(url):\n",
    "    \"\"\"\n",
    "    Match data taken by url and first two tables in the url.\n",
    "    Returns a pandas series of the match data for a given game.\n",
    "    \"\"\"\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "    tables = soup.findAll(\"table\", attrs={'class':\"sortable\"})[:2]\n",
    "\n",
    "    # Create the game data frame and return as a series\n",
    "    return pd.merge(*[# Create pandas series of the ‘totals’ row binding totals as the key\n",
    "                      pd.Series([cell.text.strip() \n",
    "                                 for cell in table_row.findAll('td')[:-1]], \n",
    "                                 index=data_index).to_frame().transpose().set_index(\"BindKey\")\n",
    "                      # Do this for home and away team\n",
    "                      for table in tables\n",
    "                      # Iterate through each row of the table\n",
    "                      for table_row in table.select(\"tr\")\n",
    "                      # But make sure we do this only for the last row\n",
    "                      # List comprehensions can make order confusing sometimes\n",
    "                      if len(table_row.findAll('td')) > 0 and \n",
    "                         table_row.findAll('td')[0].text == \"Totals\"],\n",
    "                      # Parameters of pd_concat set first table to home side.\n",
    "                      # And second table to the away side. \n",
    "                      # Then drop the bind key and return as series\n",
    "                      left_index=True, right_index=True,\n",
    "                      suffixes=[\"_home\", \"_away\"]).reset_index(drop=True).squeeze()\n",
    "\n",
    "def get_match_metadata(table):\n",
    "    \"\"\"\n",
    "    Get metadata for a given game\n",
    "    Also gets the match data whilst at it.\n",
    "    Returns the metadata and match data as pandas series.\n",
    "    \"\"\"\n",
    "    home, away = table.select(\"tr\")\n",
    "    Team_home, Quarters_home, Total_home, Date = [td.text \n",
    "                                                  for td in home.findAll(\"td\")]\n",
    "    Date = ' '.join(Date.split(\" \", 4)[:-1])\n",
    "    Team_away, Quarters_away, Total_away, na = [td.text \n",
    "                                                for td in away.findAll(\"td\")]\n",
    "    metadata_series = pd.Series([Date, Team_home, Team_away, \n",
    "                                 Quarters_home, Quarters_away, \n",
    "                                 Total_home, Total_away], \n",
    "                                index=metadata_index)\n",
    "    # Get data for game.\n",
    "    data_url = os.path.join(\"https://afltables.com/afl/seas/\", away.findAll(\"td\")[-1].contents[-2]['href'])\n",
    "    data_table = get_match_data(data_url)\n",
    "    # Merge the two dataframes.\n",
    "    return pd.concat([metadata_series, data_table], axis='rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from afl tables\n",
    "\n",
    "Get all the tables that contain match stats, these are the ones with the games.  \n",
    "Remove the last nine games as we just want the home and away season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalise website to query from\n",
    "r = requests.get(\"https://afltables.com/afl/seas/2017.html\")\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "# Get list of games\n",
    "games = [game \n",
    "          for game in soup.findAll(\"table\", attrs={'border':'1', 'style':\"font: 12px Verdana;\"})\n",
    "          if \"Match stats\" in game.text][:-9]  # Last 9 games are finals\n",
    "\n",
    "# Generate a dataframe, obtaining the metadata, and subsquently the match data.\n",
    "df = pd.concat([get_match_metadata(game)\n",
    "                for game in games],\n",
    "               axis='columns').transpose()\n",
    "\n",
    "# Convert date column to standard datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write data to csv file\n",
    "Result is a dataframe with each row representing a match \n",
    "and the column representing a stat of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(os.path.dirname(os.path.realpath(\"__file__\")), os.pardir, \"data\", \"stats.2017.csv\")\n",
    "df.to_csv(csv_path, sep=\",\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "725px",
    "left": "0px",
    "right": "1228px",
    "top": "106px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
